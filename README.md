# LibRAG
LibRAG是一款突破传统RAG架构的通用智能内容召回引擎，通过​​全链路模型推理能力​​重构文档预处理与段落召回流程。产品摒弃了嵌入模型、向量数据库等复杂组件，直接利用大语言模型（LLM）的深层语义理解能力实现端到端的精准检索与召回，适用于企业知识管理、专业领域问答、合规性审查、医疗病例检索、金融风控、AI智能体等多种AI应用场景。

# 架构概览
![image](https://github.com/user-attachments/assets/fdfc14c7-8d39-4fb4-9955-c8f59ca598f8)


# 核心技术突破
## 1.文档智能预处理引擎​​
​​动态结构化解析​​：支持PDF、Word、TXT、MarkDown等多格式文档的自动化解析，采用混合分割算法（滑动窗口+语义边界识别）生成连贯的文本块，解决传统分块导致的语义割裂问题。

​​内容质量增强​​：内置LLM多智能体、可实现预处理内容纠错、敏感信息脱敏，确保输入数据的完整性与合规性（如医疗文档中的患者信息自动匿名化）。

## 2.推理驱动的段落召回机制​​​​
语义推理匹配​​：通过模型直接分析用户查询与文档段落的多维度关联，替代传统向量相似度计算，可识别隐性逻辑关系（如因果链、对比论证）。

​​混合召回策略​​：融合关键词命中与深度语义推理评分，通过自研权重算法实现精准内容定位，召回准确率较传统方法提升40%以上。

## 3.AI原生的索引结构
创新索引结构：不依赖嵌入模型、向量数据库、图数据库，首创AI原生的高效索引结构，更适配大语言模型技术特点。

## 4.自成长免维护架构​​
自成长​​：文档库修改后直接触发知识库索引微调，常规文档在分钟级内完成知识同步，满足金融、法律等领域的时效性要求。

​​免维护：精准性不会随着文档增加而降低，不依赖于人工优化与干预。

# 对比传统RAG的核心优势
![image](https://github.com/user-attachments/assets/f2a52edc-783f-4a13-ad99-104d5b2afe7f)

# 技术难点-精准RAG

## 多跳问题:
所谓“多跳问题”，就是需要从多个数据源或多个步骤中提取信息，最终才能得到答案。比如，你可能需要从一堆报表中找出企业近三年的复合增长率，还要与竞争对手的发展情况进行比较。

## 路由问题:
相似文件（如不同年份的财报）在内容上非常接近，容易导致关键信息（如年份）在数据处理过程中丢失，从而影响最终结果的准确性。

## 结构化数据处理:
企业中有大量结构化数据（如数据库、Excel），如何在不损失精度的情况下与RAG结合是个挑战。

## 技术边界:
RAG只是应用的一部分，如何与其他技术（如function call）无缝协作，而不是过度依赖RAG。
